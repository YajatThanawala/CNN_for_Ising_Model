{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57952759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "896c5913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metropolis algorithm: 2D lattice of N points with, minus edges, each point has n=4 neighbours \n",
    "def energy_delta_wrap_around(state, i, j):\n",
    "    #i,j = (x,y) are the coordinates of the dipole we will flip, that we picked at random. Note, (0,0) is the bottom left\n",
    "    #state is the current state of the system, which we will now flip\n",
    "    #I am working in units of epsilon/boltzmann constant\n",
    "    side_length=np.size(state[0,:])\n",
    "    if i==0:\n",
    "        left=state[side_length-1, j]\n",
    "    else:\n",
    "        left=state[i-1,j]\n",
    "    if i==side_length-1:\n",
    "        right=state[0,j]\n",
    "    else:\n",
    "        right=state[i+1,j]\n",
    "    if j==0:\n",
    "        bottom=state[i, side_length-1]\n",
    "    else:\n",
    "        bottom=state[i,j-1]\n",
    "    if j==side_length-1:\n",
    "        top=state[i, 0]\n",
    "    else:\n",
    "        top=state[i,j+1]\n",
    "    energy_delta=2*state[i,j]*(top+bottom+right+left)\n",
    "    return energy_delta \n",
    "\n",
    "def initial_state_generator(N):\n",
    "    #N is the length of the square lattice\n",
    "    state=np.zeros(shape=(N,N))\n",
    "    for i in range(0, N):\n",
    "        for j in range(0,N):\n",
    "            p=np.random.uniform(0,1)\n",
    "            if p<=1/2:\n",
    "                state[i,j]=-1\n",
    "            else:\n",
    "                state[i,j]=1\n",
    "    return state\n",
    "def visualize(state):\n",
    "    plt.imshow(state, cmap='gray', alpha=1, origin='lower')\n",
    "\n",
    "def energy_of_state(state):\n",
    "    side_length=int(np.size(state[0,:]))\n",
    "    energy=0\n",
    "    for i in range(0, side_length):\n",
    "        for j in range(0,side_length):\n",
    "            if i==0:\n",
    "                left=state[side_length-1, j]\n",
    "            else:\n",
    "                left=state[i-1,j]\n",
    "            if i==side_length-1:\n",
    "                right=state[0,j]\n",
    "            else:\n",
    "                right=state[i+1,j]\n",
    "            if j==0:\n",
    "                bottom=state[i, side_length-1]\n",
    "            else:\n",
    "                bottom=state[i,j-1]\n",
    "            if j==side_length-1:\n",
    "                top=state[i, 0]\n",
    "            else:\n",
    "                top=state[i,j+1]\n",
    "            energy+=-1*state[i,j]*(top+right+bottom+left)\n",
    "    return energy/2 #compensates for double counting each energy \n",
    "def magnetization_of_state(state):\n",
    "    side_length=int(np.size(state[0,:]))\n",
    "    s=0\n",
    "    for i in range(0, side_length):\n",
    "        for j in range(0,side_length):\n",
    "            s+=state[i,j]\n",
    "    return s\n",
    "    \n",
    "            \n",
    "def run_metropolis(N, T, dipole_flips_per_run, skip_animation_steps, show_plot=False):\n",
    "    #N is the lattice dimension, T is the Temperature, show_plot controls whether we periodically plot the state\n",
    "    #We cant simulate T=0\n",
    "    #dipole_flips_per_run counts how many times we would like to flip each dipole in a run, very very roughly. \n",
    "    state=initial_state_generator(N)\n",
    "    iter_range=dipole_flips_per_run*N*N\n",
    "    S_state=np.zeros(iter_range)\n",
    "    U_state=np.zeros(iter_range)\n",
    "    for i in range(0,iter_range):\n",
    "        S_state[i]=magnetization_of_state(state)\n",
    "        U_state[i]=energy_of_state(state)\n",
    "        flip_coords=(np.random.randint(low=0, high=N), np.random.randint(low=0, high=N))\n",
    "        delta_energy=energy_delta_wrap_around(state, flip_coords[0], flip_coords[1])\n",
    "        #Now we implement the actual logic of the Metropolis Algorithm\n",
    "        if delta_energy<=0:\n",
    "            #When the energy change is negative, always flip the given coordinate\n",
    "            state[flip_coords[0], flip_coords[1]]=-1*state[flip_coords[0], flip_coords[1]]\n",
    "        else:\n",
    "            #When the energy is positive, calculate flip probability based on boltzmann factor. Change state accordingly\n",
    "            p_flip=np.exp((-1*delta_energy)/T)\n",
    "            if np.random.rand()<=p_flip:\n",
    "                state[flip_coords[0], flip_coords[1]]=-1*state[flip_coords[0], flip_coords[1]]\n",
    "        \n",
    "        if show_plot and i%skip_animation_steps==0:\n",
    "            clear_output(wait=True)\n",
    "            plt.imshow(state, cmap='gray', alpha=1, origin='lower')\n",
    "            plt.show()\n",
    "    return state, U_state, S_state\n",
    "            \n",
    "def find_average(U_state):\n",
    "    #Given a np array of all energies that are 'seen' in a metropolis run, this function returns the weighted\n",
    "    #average of all energies \n",
    "    #Exactly the same function applies for the magnetization, except with s_state passed in\n",
    "    u_max=int(np.amax(U_state))\n",
    "    u_min=int(np.amin(U_state))\n",
    "    frequencies=np.zeros(int(1+u_max-u_min))\n",
    "    for i in range(u_min, u_max+1):\n",
    "        for item in U_state:\n",
    "            if item==i:\n",
    "                frequencies[i-u_min]+=1\n",
    "    weighted_sum=0\n",
    "    for i in range(0, np.size(frequencies)):\n",
    "        weighted_sum+=frequencies[i]*(u_min+i)\n",
    "    avg=(1/np.size(U_state))*weighted_sum\n",
    "    return avg\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f640f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the metropolis code above as generator of data samples, we will now attempt to teach a CNN to predict \n",
    "#average magnetization and energy. For Now, i will fix N, because I will pass in the final state of the network\n",
    "#defining the data generating functions:\n",
    "def generate_single_image_without_specifying_T(N):\n",
    "    T=np.random.randint(1, 11)\n",
    "    dipole_flips_per_run=100\n",
    "    img, U, S= run_metropolis(N, T, dipole_flips_per_run, 1)\n",
    "    training_result=np.array([find_average(U), find_average(S)])\n",
    "    return img, training_result\n",
    "def generate_batch_of_images_without_specifying_T(N, batchsize=30):\n",
    "    batch_training_data=np.zeros(shape=(batchsize, N, N))\n",
    "    batch_training_result=np.zeros(shape=(batchsize,2))\n",
    "    for i in range(batchsize):\n",
    "        batch_training_data[i,:,:],batch_training_result[i,:]=generate_single_image_without_specifying_T(N)\n",
    "    return batch_training_data, batch_training_result\n",
    "#Generate only average energies. We know from mean-field approach that magnetization and temperature aren't related.\n",
    "#in a continuos fashion. So, it doesn't make much sense to have a network predict magnetization. \n",
    "\n",
    "def generate_single_sample_only_U_no_T(N):\n",
    "    T=np.random.randint(1, 11)\n",
    "    dipole_flips_per_run=100\n",
    "    img, U, S= run_metropolis(N, T, dipole_flips_per_run, 1)\n",
    "    training_result=find_average(U)\n",
    "    return img, training_result\n",
    "\n",
    "def generate_batch_only_U_no_T(N, batchsize=15):\n",
    "    batch_training_data=np.zeros(shape=(batchsize, N, N))\n",
    "    batch_training_result=np.zeros(batchsize)\n",
    "    for i in range(batchsize):\n",
    "        batch_training_data[i,:,:],batch_training_result[i]=generate_single_sample_only_U_no_T(N)\n",
    "    return batch_training_data, batch_training_result\n",
    "\n",
    "#Now, we try to tell the network the temperature at which the picture is taken. i.e. we will use a 2 channel input.\n",
    "#Second channel indicates temperature. \n",
    "\n",
    "def generate_sample_U_and_T(N):#This function doesn't exactly generate a single sample because it returns T as a number\n",
    "    #Use batchsize=1 in the next function to get a single sample\n",
    "    T=np.random.randint(1, 11)\n",
    "    dipole_flips_per_run=100\n",
    "    img, U, S= run_metropolis(N, T, dipole_flips_per_run, 1)\n",
    "    training_result=find_average(U)\n",
    "    return img, T, training_result\n",
    "\n",
    "def generate_batch_U_and_T(N, batchsize=15):\n",
    "    batch_training_data=np.zeros(shape=(batchsize, N, N, 2))\n",
    "    batch_training_result=np.zeros(batchsize)\n",
    "    for i in range(batchsize):\n",
    "        img, T, U=generate_sample_U_and_T(N)\n",
    "        intermediate=np.zeros(shape=(N,N,2))\n",
    "        intermediate[:,:,0]=img\n",
    "        intermediate[:,:,1]=T\n",
    "        batch_training_data[i,:,:,:]=intermediate\n",
    "        batch_training_result[i]=U\n",
    "    return batch_training_data, batch_training_result\n",
    "    \n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29557a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 12:37:04.675724: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Defining the network\n",
    "N=5\n",
    "batchsize=15\n",
    "Net=keras.models.Sequential()\n",
    "Net.add(keras.layers.Conv2D(3,3,input_shape=(N,N,1), padding='same', activation='tanh'))\n",
    "Net.add(keras.layers.AveragePooling2D(pool_size=(2,2), padding='same'))\n",
    "Net.add(keras.layers.Conv2D(6,3, padding='same', activation='tanh'))\n",
    "Net.add(keras.layers.AveragePooling2D(pool_size=(2,2), padding='same'))\n",
    "Net.add(keras.layers.Conv2D(1,3, padding='same', activation='tanh'))\n",
    "Net.add(keras.layers.Flatten())\n",
    "Net.add(keras.layers.Dense(100, activation='tanh'))\n",
    "Net.add(keras.layers.Dense(50, activation='tanh'))\n",
    "Net.add(keras.layers.Dense(25, activation='softsign'))\n",
    "Net.add(keras.layers.Dense(1,activation='linear'))\n",
    "Net.compile(loss='mean_squared_error', optimizer='adam', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7d6ba8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "#Training the network in the simple case of only passing in final state. \n",
    "epochs=100\n",
    "batchsize=15\n",
    "N=5\n",
    "costs=np.zeros(epochs)\n",
    "for i in range(epochs):\n",
    "    batch, result=generate_batch_only_U_no_T(N, batchsize=15)\n",
    "    costs[i]=Net.train_on_batch(batch, result)\n",
    "print('done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aff889e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, we define a similar CNN, with the only change \n",
    "#that we add a channel that informs the network about the temperature\n",
    "N=5\n",
    "batchsize=15\n",
    "NewNet=keras.models.Sequential()\n",
    "NewNet.add(keras.layers.Conv2D(3,3,input_shape=(N,N,2), padding='same', activation='softsign'))\n",
    "NewNet.add(keras.layers.AveragePooling2D(pool_size=(2,2), padding='same'))\n",
    "NewNet.add(keras.layers.Conv2D(6,3, padding='same', activation='softsign'))\n",
    "NewNet.add(keras.layers.AveragePooling2D(pool_size=(2,2), padding='same'))\n",
    "NewNet.add(keras.layers.Conv2D(1,3, padding='same', activation='softsign'))\n",
    "NewNet.add(keras.layers.Flatten())\n",
    "NewNet.add(keras.layers.Dense(100, activation='tanh'))\n",
    "NewNet.add(keras.layers.Dense(25, activation='softsign'))\n",
    "NewNet.add(keras.layers.Dense(1))\n",
    "NewNet.compile(loss='mean_squared_error', optimizer='adam', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "346b6b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "#training the network. We want it to predict the average energy, given final state and temperature at Ising model\n",
    "epochs=100\n",
    "batchsize=15\n",
    "N=5\n",
    "costs=np.zeros(epochs)\n",
    "for i in range(epochs):\n",
    "    batch, result=generate_batch_U_and_T(N, batchsize=15)\n",
    "    costs[i]=NewNet.train_on_batch(batch, result)\n",
    "print('done!')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a464612b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86be1c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8063aa85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061059bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
